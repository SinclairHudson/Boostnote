{"_id":"note:ektuh5h6H","title":"Metrics","content":":::note Precision\n\n$$Precision = \\frac{TP}{TP + FP}$$\n\nPrecision is \"what proportion of positive identifications are actually correct?\"\n\nPrecision is hampered by false positives.\nPrecision is used in classication tasks, where the problem is simplified into binary classification.\n\n:::\n\n:::note Recall\n\n$$Recall = \\frac{TP}{TP + FN}$$\n\nRecall is \"what proportion of actual positives are identified correctly?\"\n\nRecall is hampered by false negatives, so if you miss certain instances.\n\nUsed in classification settings, including binary classification.\n\n\n:::\n\n:::note Confusion Matrix\n\nA really good visualisation for classification tasks:\n\n![](image-kl85fco6.png)\n\nPrecision is the correct box over the sum of the column.\n\nRecall is the correct box over the sum of the row. **Recall = ROW**.\n\nSo for class 2 in this example, the precision is \n$$\\frac{659}{3+18+659+36+63} = 0.84$$\n\nFor class 2, the recall is \n$$\\frac{659}{125+34+659+29+153} = 0.659$$\n\nSo we can say that the system doesn't do a great job at classifying all class 2 instances at such (meh recall), however when it does predict 2, it's usually correct (high precision).\n:::","tags":[],"folderPathname":"/ML","data":{},"createdAt":"2021-02-16T15:10:05.692Z","updatedAt":"2021-02-16T15:22:43.608Z","trashed":false,"_rev":"c0VhzxfyA"}