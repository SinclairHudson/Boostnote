{"title":"Dynamic Programming","content":"# Dynamic Programming\n\n![](image-kksen5sw.png)\n\nObviously, the right is much better. So much repeated work on the left. \n\nJust count up, it's wayyyy faster.\n\n:::note Dynamic programming\nSolve subproblems from smaller to larger, storing up solutions.\n:::\n\n![](image-kkseqi5p.png)\n\n![](image-kksh04to.png)\n\n---\n\n![](image-kksh1h0k.png)\n\n![](image-kksh80mv.png)\n\n![](image-kksh9i7m.png)\n\n---\n\n![](image-kkshbfsv.png)\n\n![](image-kkshh02y.png)\n\n![](image-kkshmb1s.png)\n\nThere's a reduction!\n\n![](image-kkshnafn.png)\n\n---\n\n:::note edit distance\nthe number of changes you need to make to move from one string to another.\n:::\n\n![](image-kkx8erbq.png)\n\n\n![](image-kkx8i7oe.png)\n\n\n![](image-kkxeatv6.png)\n\n![](image-kkxeci5g.png)\n\n![](image-kkxefb1l.png)\n\n![](image-kkxej84n.png)\n\n![](image-kkxekm7t.png)\n\n![](image-kkxen0q5.png)\n\n\n---\n\n### Constructing Optimium Binary Search Trees\n\nprobabilities of being searched are different.\n\n![](image-kl9t9k9w.png)\n\nThe dynamic approach here is to just optimize the sub trees, and recursively go up.\n\nThere are $\\theta(n^2)$ sub-problems. We'll order them by size.\nWe do the smaller ones first, and then we try all $k$ for the root. We've previously computed the sub trees, so we just look with the pair that creates the most optimal sub tree.\n\nOf course, we have our solution table:\n\n![](image-kl9tqzpy.png)\n\n---\n\nKnapsack problem:\n\n![](image-kl9u2rn2.png)\n\n![](image-kl9u72ju.png)\n\n![](image-kl9vm04w.png)\n\n![](image-kl9vms0u.png)\n\n:::note Memoization\nStore problems that you've already done, to reduce duplicate calls.\n\n:::\n\n","tags":[],"folderPathname":"/CS341","data":{},"createdAt":"2021-02-05T14:49:05.150Z","updatedAt":"2021-02-17T20:18:01.518Z","trashed":false,"_id":"note:OziPLjyF1","_rev":"wCcfQuxf6"}